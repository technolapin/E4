{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: lab05\n",
      "OK, version v1.14.15\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab05.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Determine the step-size\n",
    "\n",
    "This assignment is composed of 10 exercises. For each solved exercise, you get the points indicated below. You need to score at least **7 points** (out of 9) to pass the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    " - Download a copy of this notebook from [Blackboard](https://esiee.blackboard.com/).\n",
    " \n",
    " \n",
    " - Run `jupyter notebook` on your computer, and open the `.ipynb` file that you just downloaded.\n",
    "\n",
    "\n",
    " - Solve the quizzes by filling in the cells with your solutions. \n",
    " \n",
    " \n",
    " - Check your answer by running the unit test provided at the end of each quiz.\n",
    " \n",
    " \n",
    " - **Get your work checked before leaving the lab, otherwise you won't get any credit for it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "| Exercise | Topic | Points |\n",
    "|----------|------|--------|\n",
    "| Warm up | Gradient descent | 0 |\n",
    "| Quiz 1.1 | Linear model | 1 |\n",
    "| Quiz 1.2 | MSE cost | 1 |\n",
    "| Quiz 1.3 | Linear regression | 1 |\n",
    "| Quiz 2.1 | Tanh model | 1 |\n",
    "| Quiz 2.2 | Tanh regression | 1 |\n",
    "| Quiz 2.3 | ReLU model | 1 |\n",
    "| Quiz 2.4 | ReLU regression | 1 |\n",
    "| Quiz 3.1 | Lipschitz constant | 1 |\n",
    "| Quiz 3.2 | Poly regression | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages\n",
    "\n",
    "For this assignment, you need to import the following packages.\n",
    "- [**Numpy**](www.numpy.org) - The library for scientific computing in Python.\n",
    "- [**Matplotlib**](http://matplotlib.org) - The library for plotting graphs in Python.\n",
    "- [**Autograd**](https://github.com/HIPS/autograd) - The library for automatic differentiation of Numpy code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up\n",
    "\n",
    "> **Complete the implementation of gradient descent with the following:**\n",
    ">\n",
    "> 1. Add the option for a diminishing stepsize, defined as:\n",
    ">\n",
    "> $$\\alpha_k = \\frac{\\alpha_0}{1+k}$$\n",
    ">\n",
    "> 2. Implement the update step using the variable stepsize:\n",
    ">\n",
    "> $$ {\\bf w} \\leftarrow {\\bf w} - \\alpha_k \\nabla J({\\bf w}). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": [
     "quiz",
     "gradient_descent"
    ]
   },
   "outputs": [],
   "source": [
    "def gradient_descent(cost_fun, w_init, alpha, epochs, stepsize=None):\n",
    "    \"\"\"Find the point that minimizes the cost function.\n",
    "    \n",
    "    INPUTS:\n",
    "    cost_fun -- Cost function | callable\n",
    "    w_init   -- Initial point | numpy array\n",
    "    alpha    -- step-size     | scalar\n",
    "    epochs   -- n. iterations | integer\n",
    "    \n",
    "    OUTPUTS:\n",
    "    w       -- final point\n",
    "    history -- sequence of iterates w0, w1, ...\n",
    "    \"\"\"\n",
    "    \n",
    "    # automatic gradient\n",
    "    from autograd import grad\n",
    "    gradient = grad(cost_fun)\n",
    "\n",
    "    # initialization\n",
    "    w = np.array(w_init).copy()\n",
    "    \n",
    "    # gradient descent\n",
    "    history = [w]   \n",
    "    for k in range(epochs):\n",
    "        \n",
    "        # update the stepsize\n",
    "        if stepsize == 'diminishing':\n",
    "            ak = alpha/(1+k)\n",
    "        else:\n",
    "            ak = alpha\n",
    "        \n",
    "        # compute the next point\n",
    "        w = w - ak*gradient(w) # YOUR CODE HERE\n",
    "        \n",
    "        # track the history\n",
    "        history.append(w)\n",
    "        \n",
    "    return w.squeeze(), np.stack(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"gradient_descent\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Linear regression\n",
    "\n",
    "The following quizzes will guide you through the solution of the optimization problem\n",
    "\n",
    "\n",
    "$$\n",
    "\\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{N+1}}\\; \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{linear-model}\\left({\\bf x}^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2\n",
    "$$\n",
    "\n",
    "for a given set of input/output pairs $({\\bf x}^{(1)},y^{(1)}), \\dots, ({\\bf x}^{(P)},y^{(P)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1.1\n",
    "\n",
    "> **Implement a function that evaluates the linear model on several input vectors $\\mathbf{x}^{(p)} \\in \\mathbb{R}^N$, namely** \n",
    ">\n",
    "> $$ \n",
    "\\textsf{linear-model}\\left({\\bf x}^{(p)}; \\mathbf{w} \\right) = w_{0} + w_1 x_1^{(p)} + \\dots + w_N x_N^{(p)} = \\mathbf{w}^\\top \\mathring{\\mathbf{x}}^{(p)}\n",
    "$$\n",
    ">\n",
    "> **for a given vector $\\mathbf{w}\\in\\mathbb{R}^{N+1}$.**\n",
    "\n",
    "> *Hint:* The function `linear_model()` takes two inputs:\n",
    "> - the weight vector $\\mathbf{w}\\in\\mathbb{R}^{N+1}$\n",
    "> - the matrix $X\\in\\mathbb{R}^{P\\times N}$ stacking the vectors ${\\bf x}^{(p)}\\in \\mathbb{R}^N$ along its rows:\n",
    ">\n",
    ">$$\n",
    "X = \\begin{bmatrix}\n",
    "\\_\\!\\_\\; {{\\bf x}^{(1)}}^\\top \\_\\!\\_ \\\\\n",
    "\\vdots \\\\\n",
    "\\_\\!\\_\\; {{\\bf x}^{(P)}}^\\top \\_\\!\\_ \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    ">\n",
    "> Consequently, the products ${\\bf w}^\\top\\mathring{\\mathbf{x}}^{(1)}, \\dots, {\\bf w}^\\top\\mathring{\\mathbf{x}}^{(P)}$ can be efficiently computed via a matrix-vector multiplication:\n",
    ">\n",
    ">$$ \n",
    "\\mathring{X} {\\bf w} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "{\\mathring{\\bf x}^{(1)}}^\\top{\\bf w}\\\\\n",
    "\\vdots\\\\\n",
    "{\\mathring{\\bf x}^{(P)}}^\\top {\\bf w}\n",
    "\\end{bmatrix}.$$\n",
    ">\n",
    "> Note however that the shapes of input arrays `X` and `w` don't align for a matrix-vector product, as\n",
    "> - `w` is a vector of shape `(N+1,)`\n",
    "> - `X` is a matrix of shape `(P,N)`. \n",
    ">\n",
    "> To circumvent this issue, you can proceed as follows:\n",
    "> - multiply `X` with the sliced elements `w[1], ..., w[N]`\n",
    "> - add `w[0]` to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": [
     "quiz",
     "linear_model"
    ]
   },
   "outputs": [],
   "source": [
    "def linear_model(x, w):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    x -- matrix of shape (P, N)\n",
    "    w -- vector of shape (N+1,)\n",
    "\n",
    "    OUTPUT:\n",
    "    y -- vector of shape (P,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute 'w[0] + w[1] * x[p,0] + ... + w[N] * x[p,N-1]' for each row of 'x'\n",
    "    y_hat = w[0] + np.sum(x*w[1:], axis=1)\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"linear_model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1.2\n",
    "\n",
    "> **Implement the following cost function:**\n",
    ">\n",
    "> $$ \\big(\\forall {\\bf w}\\in\\mathbb{R}^{N+1}\\big)\\qquad J\\left(\\mathbf{w}\\right) = \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{model}\\left({\\bf x}^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2 $$\n",
    ">\n",
    "> **where the pairs $({\\bf x}^{(p)},y^{(p)})$ are given.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": [
     "quiz",
     "mse_cost"
    ]
   },
   "outputs": [],
   "source": [
    "def mse_cost(w, x, y, model):\n",
    "    \"\"\"     Âµ\n",
    "    Inputs:\n",
    "    w -- model weights\n",
    "    x -- model inputs\n",
    "    y -- expected model outputs\n",
    "    model -- function that evaluates a model on the inputs 'x' using the weights 'w'\n",
    "    \"\"\"\n",
    "    # Evaluate the model on 'x' using the weights 'w'\n",
    "    y_pred = model(x, w) # YOUR CODE HERE\n",
    "    # Compute the mean squared error between 'y_hat' and 'y'\n",
    "    J = np.mean((y_pred-y)**2) # YOUR CODE HERE\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"mse_cost\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1.3\n",
    "\n",
    "> **Use gradient descent to solve linear regression (i.e., to find the hyperplane that best fits the given points).** \n",
    "> - **Required:** The numerical error w.r.t. the exact solution must be less than $10^{-4}$.\n",
    "\n",
    "> *Hint:* You simply need to invoke the function `gradient_descent(...)` with the following parameters.\n",
    "> - `cost_fun` - **Cost function:** it's a Python callable defined by `def` or `lambda`.\n",
    "> - `w_init` - **Initialization:** it's a list that contains `N+1` float values.\n",
    "> - `alpha` - **Step-size:** it's a scalar value between $0$ and $1$. \n",
    "> - `epochs`  - **Number of iterations:** it's an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": [
     "quiz",
     "linear_regression"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Exact solution: [1, -1, -1]\n",
      "Gradient descent: [ 1. -1. -1.]\n",
      " Numerical error: 8e-16\n"
     ]
    }
   ],
   "source": [
    "# Random-generated data\n",
    "np.random.seed(42)\n",
    "P = 50\n",
    "N = 2\n",
    "X = np.random.randn(P, N)\n",
    "y = 1 - X[:,0] - X[:,1]\n",
    "\n",
    "# Define the cost function on the given 'X' and 'y'\n",
    "linear_mse_cost = lambda w: mse_cost(w, X, y, linear_model) # YOUR CODE HERE\n",
    "\n",
    "# Set a random initialization\n",
    "w_init = np.zeros(N+1) # YOUR CODE HERE\n",
    "\n",
    "# Set the step-size\n",
    "alpha = 0.1 # YOUR CODE HERE\n",
    "\n",
    "# Set the number of iterations\n",
    "epochs = 1000 # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Perform the optimization by invoking 'gradient_descent()'\n",
    "w, history = gradient_descent(linear_mse_cost,\n",
    "                              w_init,\n",
    "                              alpha,\n",
    "                              epochs)\n",
    "\n",
    "\n",
    "# Visualize the history plot\n",
    "plt.plot([linear_mse_cost(wk) for wk in history])\n",
    "plt.title('History plot')\n",
    "plt.show()\n",
    "\n",
    "# Compare with the exact solution\n",
    "w_bar = [1, -1, -1]\n",
    "print('  Exact solution:', w_bar)\n",
    "print('Gradient descent:', w)\n",
    "print(' Numerical error: {:.0e}'.format(np.linalg.norm(w - w_bar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"linear_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Nonlinear regression\n",
    "\n",
    "The following quizzes will guide you through the solution of the optimization problem\n",
    "\n",
    "$$\n",
    "\\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{N+1}}\\; \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{nonlinear-model}\\left(x^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2\n",
    "$$\n",
    "\n",
    "for a given set of input/output pairs $(x^{(1)},y^{(1)}), \\dots, (x^{(P)},y^{(P)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.1\n",
    "\n",
    "> **Implement a function that evaluates the hyperbolic tangent model on several input values $x^{(p)} \\in \\mathbb{R}$, namely** \n",
    ">\n",
    "> $$ \n",
    "\\textsf{tanh-model}\\left(x^{(p)};\\mathbf{w}\\right) = w_{0} + w_1 \\tanh\\left(w_2 + w_3 x^{(p)}\\right),\n",
    "$$\n",
    ">\n",
    "> **for a given vector $\\mathbf{w}=[w_0,w_1,w_2,w_3]\\in\\mathbb{R}^{4}$.**\n",
    "\n",
    "> *Hint:* [`np.tanh()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.tanh.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": [
     "quiz",
     "tanh_model"
    ]
   },
   "outputs": [],
   "source": [
    "def tanh_model(x, w):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x -- vector of shape (P,)\n",
    "    w -- vector of shape (4,)\n",
    "    \n",
    "    Returns:\n",
    "    y -- vector of shape (P,)\n",
    "    \"\"\"\n",
    "\n",
    "    z = w[0]+w[1]*np.tanh(w[2]+w[3]*x) # YOUR CODE HERE\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"tanh_model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.2\n",
    "\n",
    "> **Use gradient descent to solve the following optimization problem:** \n",
    ">\n",
    "> $$ \\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{4}}\\; \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{tanh-model}\\left(x^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2, $$\n",
    ">\n",
    "> **where the pairs $(x^{(p)},y^{(p)})$ are given.**\n",
    ">\n",
    "> - **Required:** The cost function at the solution must be less than $0.09$.\n",
    "\n",
    "> *Hint:* For this problem, gradient descent needs a high number of iteration to converge. Make sure that the history plot gets \"perfectly\" flat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": [
     "quiz",
     "tanh_regression"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found by gradient descent: [ 0.93674152 -1.06827229 -0.23666633  5.55339223]\n",
      "Cost function at the solution: 0.0778227740127752\n"
     ]
    }
   ],
   "source": [
    "# Random-generated data\n",
    "np.random.seed(42)\n",
    "P = 50\n",
    "X = np.linspace(-1,1,P)\n",
    "y = 1 + np.tanh(-10*x + 0.5) + 0.3*np.random.randn(P)\n",
    "\n",
    "# Define the cost function on the given data 'x' and 'y'\n",
    "tanh_mse_cost = lambda w: mse_cost(w, X, y, tanh_model) # YOUR CODE HERE\n",
    "\n",
    "# Set a random initialization\n",
    "w_init = np.random.randn(4) # YOUR CODE HERE\n",
    "#w_init[0] = 1;\n",
    "# Set the step-size\n",
    "alpha = 0.5 # YOUR CODE HERE\n",
    "\n",
    "# Set the number of iterations\n",
    "epochs = 1000# YOUR CODE HERE\n",
    "\n",
    "# Perform the optimization by invoking 'gradient_descent()'\n",
    "w, history = gradient_descent(tanh_mse_cost,\n",
    "                              w_init,\n",
    "                              alpha,\n",
    "                              epochs)\n",
    "\n",
    "# Visualize the history plot\n",
    "plt.plot([tanh_mse_cost(wk) for wk in history])\n",
    "plt.title('History plot')\n",
    "plt.show()\n",
    "\n",
    "# Compare with the exact solution\n",
    "print('Solution found by gradient descent:', w)\n",
    "print('Cost function at the solution:', tanh_mse_cost(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"tanh_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure plots the **tanh model** (red line) using the weights estimated by gradient descent. You should observe quite a good fit to the data (blues dots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.xlabel('x', fontsize='16')\n",
    "plt.ylabel('y', fontsize='16')\n",
    "\n",
    "t = np.linspace(-1,1,100)\n",
    "plt.plot(t, tanh_model(t, w), color='r', linewidth=3, label='Tanh model')\n",
    "\n",
    "plt.legend(fontsize='14')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.3\n",
    "\n",
    "> **Implement a function that evaluates the RELU model on several input values ${\\bf x} \\in \\mathbb{R}^N$, namely** \n",
    ">\n",
    "> $$ \n",
    "\\textsf{relu-model}\\left({\\bf x};\\mathbf{w}\\right) = \n",
    "%w_0^{(0)} + w_1^{(0)} \\max\\{0, w_0^{(1)} + w_1^{(1)} x\\} + \\dots + w_B^{(0)} \\max\\{0, w_0^{(B)} + w_1^{(B)} x\\},\n",
    "w_0^{(0)} + w_1^{(0)} \\max\\big\\{0, \\mathring{\\mathbf{x}}^\\top \\mathbf{w}^{(1)} \\big\\} + \\dots + w_B^{(0)} \\max\\big\\{0, \\mathring{\\mathbf{x}}^\\top \\mathbf{w}^{(B)} \\big\\},\n",
    "$$\n",
    ">\n",
    "> **for a given set of parameters $\\mathbf{w}=(\\mathbf{w}^{(0)},\\mathbf{w}^{(1)},\\dots,\\mathbf{w}^{(B)}) \\in\\mathbb{R}^{B+1}\\times\\mathbb{R}^{N+1}\\times\\dots\\times\\mathbb{R}^{N+1}$.**\n",
    "\n",
    "> *Hints:* \n",
    "> - [`np.maximum()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "> - You may find useful the function `linear_model()` implemented in a previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": [
     "quiz",
     "relu_model"
    ]
   },
   "outputs": [],
   "source": [
    "def relu_model(x, w):\n",
    "    \"\"\"    \n",
    "    Inputs:\n",
    "    x -- matrix of shape (P, N)\n",
    "    w -- vector of shape ((N+2)*B+1,)\n",
    "    \n",
    "    Outputs:\n",
    "    y -- vector of shape (P,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure that 'x' is a matrix\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    \n",
    "    # Dimensions\n",
    "    N = x.shape[1]\n",
    "    B = (w.size - 1) // (N+2)\n",
    "    assert w.size == (N+2)*B+1\n",
    "            \n",
    "    # Select the first (N+1)*B weights and reshape them into a (N+1,B) matrix\n",
    "    w_relu = w[:(N+1)*B].reshape(N+1, B) # YOUR CODE HERE\n",
    "    \n",
    "    # Multiply 'x' by 'w_relu' --> You may use 'linear_model()'\n",
    "    z = linear_model(w_relu, x) # YOUR CODE HERE\n",
    "    \n",
    "    # Clip the negative values in 'z' to zero --> You may use 'np.maximum()'\n",
    "    relu = np.maximim(z, 0) # YOUR CODE HERE\n",
    "    \n",
    "    # Select the last B+1 weights\n",
    "    w_linear = w[len(w):] # YOUR CODE HERE\n",
    "    \n",
    "    # Multiply 'relu' by 'w_linear' --> You may use 'linear_model()'\n",
    "    y = None # YOUR CODE HERE\n",
    "     \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"relu_model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2.4\n",
    "\n",
    "> **Use gradient descent to solve the following optimization problem:** \n",
    ">\n",
    "> $$ \\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{3B+1}}\\; \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{relu-model}\\left(x^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2, $$\n",
    ">\n",
    "> **where the pairs $(x^{(p)},y^{(p)})$ are given.**\n",
    ">\n",
    "> - **Required:** The cost function at the solution must be less than $0.05$.\n",
    "\n",
    "> *Hints:* \n",
    "> - For this problem, gradient descent needs a high number of iteration to converge. Make sure that the history plot gets \"perfectly\" flat.\n",
    "> - The choice of the step-size $\\alpha$ is critical for obtaining a satisfactory result. Try different values and select the one that leads to the smallest value of the cost function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "quiz",
     "relu_regression"
    ]
   },
   "outputs": [],
   "source": [
    "# Random-generated data\n",
    "np.random.seed(42)\n",
    "P = 50\n",
    "x = np.linspace(-2,2,P)\n",
    "y = np.sin(np.pi*x - np.pi) + 0.2*np.random.randn(P)\n",
    "\n",
    "# Define the cost function on the given data 'x' and 'y'\n",
    "relu_mse_cost = None # YOUR CODE HERE\n",
    "\n",
    "# Set a random initialization\n",
    "np.random.seed(5)\n",
    "B = 100\n",
    "w_init = None # YOUR CODE HERE\n",
    "\n",
    "# Set the step-size\n",
    "alpha = None # YOUR CODE HERE\n",
    "\n",
    "# Set the number of iterations\n",
    "epochs = None # YOUR CODE HERE\n",
    "\n",
    "# Perform the optimization by invoking 'gradient_descent()'\n",
    "... # YOUR CODE HERE\n",
    "\n",
    "# Visualize the history plot\n",
    "plt.plot([relu_mse_cost(wk) for wk in history])\n",
    "plt.title('History plot')\n",
    "plt.show()\n",
    "\n",
    "# Compare with the exact solution\n",
    "print('Cost function at the solution:', relu_mse_cost(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"relu_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure plots the **relu model** (red line) using the weights estimated by gradient descent. You should observe quite a good fit to the data (blues dots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.xlabel('x', fontsize='16')\n",
    "plt.ylabel('y', fontsize='16')\n",
    "\n",
    "t = np.linspace(-2.1,2.1,100)\n",
    "plt.plot(t, relu_model(t, w), color='r', linewidth=3, label='Relu model')\n",
    "\n",
    "plt.legend(fontsize='14')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Polynomial regression\n",
    "\n",
    "The following quizzes will guide you through the solution of the optimization problem\n",
    "\n",
    "$$\n",
    "\\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{N+1}}\\; \\frac{1}{P}\\sum_{p=1}^{P}\\Big(\\textsf{poly-model}\\left(x^{(p)}; \\mathbf{w}\\right) - y^{(p)} \\Big)^2\n",
    "$$\n",
    "\n",
    "for a given set of input-output pairs $(x^{(1)},y^{(1)}), \\dots, (x^{(P)},y^{(P)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3.1\n",
    "\n",
    "> **For a given matrix $X$, compute the Lipschitz constant of the function $J\\left(\\mathbf{w}\\right) = \\frac{1}{P} \\| X\\mathbf{w}-\\mathbf{y} \\|^2$, which is given as:**\n",
    ">\n",
    "> $$ L = \\frac{2}{P} \\| X^\\top X \\|_2. $$\n",
    "\n",
    "> Hints:\n",
    "> - $\\|A\\|_2$ denotes the maximum eigenvalue of the symmetric matrix $A$.\n",
    "> - [`np.linalg.eigh()`](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.eigh.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "quiz",
     "lipschitz"
    ]
   },
   "outputs": [],
   "source": [
    "# Random-generated data\n",
    "np.random.seed(42)\n",
    "P = 50\n",
    "x = np.linspace(0,8,P)\n",
    "y = 0.2*x**2 + 0.1*x + np.random.randn(P)\n",
    "\n",
    "# Polynomial transformation\n",
    "d = 2\n",
    "X_poly = np.stack([x**i for i in range(d+1)], axis=1)\n",
    "\n",
    "# Lipschitz constant\n",
    "... # YOUR CODE HERE\n",
    "L = None # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"lipschitz\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3.2\n",
    "\n",
    "> **Use gradient descent to solve the following optimization problem:** \n",
    ">\n",
    "> $$ \\operatorname*{minimize}_{\\mathbf{w}\\in\\mathbb{R}^{3}}\\; \\frac{1}{P} \\| X\\mathbf{w}-\\mathbf{y} \\|^2 $$\n",
    ">\n",
    "> **where $X\\in\\mathbb{R}^{P\\times 3}$ and $y\\in\\mathbb{R}^{3}$ are given.**\n",
    ">\n",
    "> - **Required:** The cost function at the solution must be less than $1$.\n",
    "\n",
    "> *Hints:* \n",
    "> - For this problem, gradient descent needs a high number of iteration to converge. Make sure that the history plot gets \"perfectly\" flat.\n",
    "> - Use the Lipschitz constant $L$ to set the step-size as $\\alpha = \\frac{1}{L}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "quiz",
     "poly_regression"
    ]
   },
   "outputs": [],
   "source": [
    "# Define the cost function on the given data 'X_poly' and 'y'\n",
    "poly_mse_cost = None # YOUR CODE HERE\n",
    "\n",
    "# Set a random initialization\n",
    "np.random.seed(42)\n",
    "w_init = None # YOUR CODE HERE\n",
    "\n",
    "# Set the step-size\n",
    "alpha = None # YOUR CODE HERE\n",
    "\n",
    "# Set the number of iterations\n",
    "epochs = None # YOUR CODE HERE\n",
    "\n",
    "# Perform the optimization by invoking 'gradient_descent()'\n",
    "... # YOUR CODE HERE\n",
    "\n",
    "# Visualize the history plot\n",
    "plt.plot([poly_mse_cost(wk) for wk in history])\n",
    "plt.title('History plot')\n",
    "plt.show()\n",
    "\n",
    "# Compare with the exact solution\n",
    "print('Cost function at the solution:', poly_mse_cost(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"poly_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure plots the **poly model** (red line) using the weights estimated by gradient descent. You should observe quite a good fit to the data (blues dots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.xlabel('x', fontsize='16')\n",
    "plt.ylabel('y', fontsize='16')\n",
    "\n",
    "t = np.linspace(-1,9,100)\n",
    "X_test = np.stack([t**i for i in range(d+1)], axis=1)\n",
    "\n",
    "plt.plot(t, X_test@w, color='r', linewidth=3, label='Poly model')\n",
    "\n",
    "plt.legend(fontsize='14')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
